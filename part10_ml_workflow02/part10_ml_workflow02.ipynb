{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53f6fbb0-49f1-4a04-b450-cd567cc20fc1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Grundlegender ML-Workflow mit Scikit-Learn \n",
    "\n",
    "Im letzten Kapitel haben wir uns mit den Basisbegriffen des maschinellen Lernens beschäftigt:\n",
    "* überwachtes Lernen (supervised learning)\n",
    "* unüberwachtes Lernen (unsupervised learning)\n",
    "\n",
    "sowie Input (Eigenschaft, Merkmal, Feature oder Attribut) und Output (Klassenbezeichnung, Kategorie, Label, Target, Zielwert). Mit der linearen Regression haben wir ein einfaches Beispiel für überwachtes Lernen kennengelernt. Zur Erinnerung hier noch einmal der grundlegende Ablauf eines ML-Projektes, bevor wir uns weitere Beispiele zur Klassifikation und zum Clustering ansehen werden. \n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<ol>\n",
    "<li>Zuerst wählen wir ein Modell aus, das trainiert werden soll. </li>\n",
    "<li>Danach wählen wir die Hyperparameter des Modells aus. Hyperparameter sind Parameter des Modells, die wir vorab ohne Kenntnis der Daten festlegen.</li>\n",
    "<li>Danach packen wir die Inputdaten in eine Matrix X, bei der jede Spalte eine Eigenschaft repräsentiert und in den Zeilen die Daten stehen.</li>\n",
    "<li>Falls wir ein überwachtes Lernverfahren anwenden wollen, packen wir die Outputdaten in einen Zeilenvektor y.</li>\n",
    "<li>Wir trainieren das ML-Modell, indem wir die fit()-Methode aufrufen.</li>\n",
    "<li>Um das Modell zur Prognose neuer Daten zu verwenden, benutzten wir die predict()-Methode</li>\n",
    "</ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d0862b-4e6b-472a-8c34-687c5cc8c911",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns; sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a841a69f-c429-4535-90ee-db043f08c6b9",
   "metadata": {},
   "source": [
    "### Einfache Klassifikation mit Scikit-Learn\n",
    "\n",
    "Um an einem einfachen Beispiel die Vorgehensweise für Klassifikationsaufgaben vorzustellen, verwenden wir ein sehr bekanntes Beispiel aus dem maschinellen Lernen, die Klassifikation von Irisblumen. Der Iris-Datensatz wird bereits seit 1936 genutzt, um Klassifikationsverfahren zu testen, siehe https://en.wikipedia.org/wiki/Iris_flower_data_set. In dem Datensatz sind drei verschiedene Irisarten:\n",
    "\n",
    "Iris setosa | Iris versicolor | Iris virginica\n",
    "- | - | -\n",
    "<img src=\"pics/fig10_iris_setosa.jpg\" alt=\"Iris setosa\" style=\"width: 200px;\"/> | <img src=\"pics/fig10_iris_versicolor.jpg\" alt=\"Iris versicolor\" style=\"width: 200px;\"/> | <img src=\"pics/fig10_iris_virginica.jpg\" alt=\"Iris vriginica\" style=\"width: 200px;\"/>\n",
    "\n",
    "Quelle linkes Bild: CC BY-SA 3.0, https://commons.wikimedia.org/w/index.php?curid=170298, ansonsten lizenzfrei\n",
    "\n",
    "Für jede dieser drei Arten gibt es 50 Beispiele, bei denen vier Eigenschaften erfasst sind:\n",
    "\n",
    "* sepal_length: Länge des Kelchblatts in cm\n",
    "* sepal_width: Breite des Kelchblatts in cm\n",
    "* petal_length: Länge des Kronblatts in cm\n",
    "* petal_width: Breite des Kronblatts in cm\n",
    "\n",
    "Da dieses Beispiel so häufig verwendet wird, ist es sogar in Scikit-Learn hinterlegt und die Iris-Daten können direkt geladen werden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed46005-5c06-45ea-85ec-8d18368ae1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "iris"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9659db3b-76c3-48df-a35c-4dc23080e810",
   "metadata": {},
   "source": [
    "Nach dem Laden des Iris-Datensatzes stellen wir fest, dass die Variable `iris` nun ein Dictionary enthält. Wir können also mit eckigen Klammern auf die einzelnen Bestandteile des Datensatzes zugreifen. In `data` stehen die Eingabedaten, in `target`die Ausgabedaten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161103f3-b7d8-4a84-99c0-6a40b0c7c395",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris['data']\n",
    "print('Dimension von X: ', np.shape(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67618857-7b97-4eb4-b380-13d3f5bf18bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = iris['target']\n",
    "print('Dimension von y: ', np.shape(y)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2f71a5-9ed5-445c-b434-fab87bdfb2d9",
   "metadata": {},
   "source": [
    "Wenn wir uns den Inhalt von `y` betrachten, stellen wir fest, dass dort nicht etwa 'setosa', 'versicolor' oder 'virginica' steht, sondern nur 0, 1 oder 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4aa2ab4-8cda-4ecd-b865-8f40acb0486b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a734cb2-73c3-4b6b-9bea-19e35dca1c91",
   "metadata": {},
   "source": [
    "Für die mathematischen ML-Algorithmen müssen wir die Kategorien, d.h. in diesem Fall die drei Iris-Arten, codieren. Damit ist gemeint, dass jede Kategorie einen Zahlencode bekommt. Hier steht also die 0 für Iris setosa, 1 für Iris versicolor und 2 für Iris virginica.\n",
    "\n",
    "Erkunden wir zunächst die Daten. Wir nehmen immer zwei Eigenschaften und stellen die Iris-Art über die Farbe dar, Scatterplots! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b9ac05-c27d-4097-87ea-1934fc42471e",
   "metadata": {},
   "source": [
    "**Mini-Übung:**\n",
    "\n",
    "Plotten Sie auf der x-Achse \"Länge Kelchblatt\", auf der y-Achse \"Breite Kelchblatt\" und färben Sie die Kreise je nach Iris-Art ein. Erstellen Sie anschließend eine zweite Grafik mit \"Länge Kelchblatt\" auf der x-Achse und \"Breite Kronblatt\" auf der y-Achse, wieder mit der Iris-Art als Einfärbung."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914e10a7-b5f1-4ec4-96d6-d098eb4876a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier Ihr Code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1628fb7-9cc6-4198-89e6-d2774fcb0105",
   "metadata": {},
   "source": [
    "Da es mühsam ist, alle Kombinationen von Hand zu bilden, lassen wir das Python machen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca78bfea-3bba-450c-90e5-5a540d72c1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "merkmale = ['Länge Kelchblatt (cm)', 'Breite Kelchblatt (cm)', 'Länge Kronblatt (cm)', 'Breite Kronblatt (cm)']\n",
    "\n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.scatter( X[:,i], X[:,j], c=y )\n",
    "        ax.set_xlabel(merkmale[i])\n",
    "        ax.set_ylabel(merkmale[j]);\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc81a439-961f-4b7f-8a54-5ba8e749fd26",
   "metadata": {},
   "source": [
    "Als nächstes wählen wir ein Modell mit Hyperparametern und trainieren es. Diesmal wird es aber schwierig zu testen, ob das trainierte Modell gute Prognosen liefert. Daher legen wir von Anfang einige der Datensätze zur Seite. Diese Daten nennen wir **Testdaten**. Mit den übriggebliebenen Daten trainieren wir das ML-Modell. Diese Daten nennen wir **Trainingsdaten**. Später nutzen wir dann die Testdaten, um zu überprüfen, wie gut das Modell funktioniert.\n",
    "\n",
    "Für die Aufteilung in Trainings- und Testdaten nehmen wir eine maßgeschneiderte Funktion von Scikit-Learn namens `train_test_split`, siehe auch https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f57740-16ae-41f7-966f-fc4185010622",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "print('Dimension X_train: ', np.shape(X_train))\n",
    "print('Dimension X_test: ',  np.shape(X_test))\n",
    "print('Dimension y_train: ', np.shape(y_train))\n",
    "print('Dimension y_test: ',  np.shape(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8fd5797-4b39-46a0-91b3-c5e54fd4e40a",
   "metadata": {},
   "source": [
    "Jetzt können wir ein ML-Modell wählen. Eines der einfachsten Klassifikationsmodelle ist das Gaußsche naive Bayes Modell, auch wenn der Name überhaupt nicht einfach ist. \n",
    "> https://scikit-learn.org/stable/modules/naive_bayes.html\n",
    "\n",
    "Dafür hat es gar keine Hyperparameter und kann direkt eingesetzt werden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343d865b-7ef4-4f83-b140-5221af2a7bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "model = GaussianNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074733ca-d14d-42c7-be2b-6238f50309d5",
   "metadata": {},
   "source": [
    "Jetzt das Training mit den Trainingsdaten (!):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a74626b-1460-43c9-9a74-35c7ae95dc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e271d8-fea6-4d5a-bfd8-306be5f3258b",
   "metadata": {},
   "source": [
    "Nun können wir testen, wie gut das Training funktioniert hat, indem wir mit dem ML-Modell prognostizieren, welche Iris-Art es für die Testdaten voraussagen würde:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af28ea1e-49af-49fd-a884-0a0da8d78c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eced9a2-43fe-41b8-9e71-5b15cc1c1ee2",
   "metadata": {},
   "source": [
    "Sehen wir uns mal die Vorhersage `y_predict` und die tatsächlichen Daten `y_test` an, die wir ja zuvor beiseite gelegt hatten:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606b309b-1a7d-4d01-ba04-3e7c7be8d78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_predict)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76c3c53-40db-40b1-b26f-5b834220b465",
   "metadata": {},
   "source": [
    "Sieht eigentlich ganz gut aus, doch an der 26. Stelle liegt unser Modell falsch. Überhaupt, das Vergleichen ist händisch etwas mühsam. Aber auch hier hilft Scikit-Learn, das eine Funktion zur Verfügung stellt, die den Anteil der korrekt prognostizierten Werte berechnet, nämlich `accuracy_score()`, siehe auch\n",
    "> https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2cb4782-0cfa-40e9-b19d-2010d612b632",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "correct = accuracy_score(y_test, y_predict)\n",
    "print('Es wurden {:.2f} % Irisblumen korrekt klassifiziert.'.format(correct*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd07e765-eef9-4ced-a330-f144ba9064fe",
   "metadata": {},
   "source": [
    "Und hier noch einmal alles zusammen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4e99cc-573a-4611-a0e6-9ad6153b3ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Module\n",
    "from sklearn import datasets\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Datenimport\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "# Auswahl des Modells mit Wahl der Hyperparameter (hier nur Standardwerte)\n",
    "model = GaussianNB()\n",
    "\n",
    "# Selektion Input und Output, Split in Trainings- und Testdaten\n",
    "X = iris['data']\n",
    "y = iris['target'] \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "# Training des ML-Modells\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Vergleich mit Messung \n",
    "y_predict = model.predict(X_test)\n",
    "\n",
    "correct = accuracy_score(y_test, y_predict)\n",
    "print('Es wurden {:.2f} % Irisblumen korrekt klassifiziert.'.format(correct*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc31dc71-1c2d-4f09-9403-8c7213333c26",
   "metadata": {},
   "source": [
    "**Mini-Übung:**\n",
    "\n",
    "Lesen Sie die Datei ``data/heart.csv`` ein. Wie viele Datensätze (=Zeilen) enthält die Datei? Die Bedeutung der Spaltennamen können Sie hier nachlesen: https://www.kaggle.com/ronitf/heart-disease-uci . Wie viele Personen leiden an einer Herzkrankheit (target == 1)?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabbb52f-0182-4109-95cc-bd180fbff846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier Ihr Code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aace662-d2a4-4c50-afa7-385e2b3466f4",
   "metadata": {},
   "source": [
    "**Mini-Übung**\n",
    "\n",
    "Extrahieren Sie nun die Input-Daten X und die Output-Daten y. Lassen Sie anschließend die Datensätze in einen Trainings- und einen Testdatensatz aufteilen. Trainieren Sie ein Gaußsches naives Bayes Modell mit den Trainingsdaten. Wenden Sie dann das trainierte Modell auf die Testdaten an. Wie viele Herzpatienten wurden in den Testdaten korrekt erkannt?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00209789-efb1-4a57-9608-34e6e16c11f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier Ihr Code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f84a13-ba0c-462b-90ee-66c8fc201563",
   "metadata": {},
   "source": [
    "**Mini-Übung**\n",
    "\n",
    "Wiederholen Sie das Training des ML-Modells. Aber nutzten Sie diemal nicht alle 13 Attribute, sondern nur das Alter (age), das Geschlecht (sex, 1 = männlich, 0 = weiblich) und den Ruhepuls (trestbps). Wie viele Herzpatienten werden nun in den Testdaten korrekt erkannt? Was prognostiziert das Modell für Sie?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4673a64d-699c-4bfe-a1c5-b8748f9db1f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "af452ce3-71b9-4146-b008-146b41049177",
   "metadata": {},
   "source": [
    "### Einfaches Clustering mit Scikit-Learn\n",
    "\n",
    "Wir verwenden für das nächste Beispiel den Iris-Datensatz weiter. Angenommen, wir wüssten nicht, dass es sich um drei Iris-Arten handelt. Eines der einfachsten Clustering-Verfahren ist das sogenannte Gauß'sche Mixture-Modell (GMM), siehe\n",
    "\n",
    "> https://scikit-learn.org/stable/modules/generated/sklearn.mixture.GaussianMixture.html#sklearn.mixture.GaussianMixture\n",
    "\n",
    "Hier müssen wir allerdings Hyperparameter setzen. Insgesamt hat GMM 14 Hyperparameter. Wichtig ist allerdings nur erste Parameter `n_components`, der die Anzahl der Cluster vorgibt.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40852cda-3e95-45f4-a5ca-1dcf1bd807e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "# Wahl des Modells\n",
    "model = GaussianMixture(n_components=3)\n",
    "\n",
    "# Training des Modells mit allen Daten\n",
    "model.fit(X)\n",
    "\n",
    "# Prognose\n",
    "y_predict = model.predict(X)\n",
    "\n",
    "print(y_predict)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437078c7-ec01-4b0c-84e4-e6ecbaa9e8e6",
   "metadata": {},
   "source": [
    "# Hyperparameter und Modellvalidierung\n",
    "\n",
    "Im letzten Abschnitt haben wir uns mit dem grundlegenden ML-Ablauf beschäftigt und als erste einfache ML-Modelle \n",
    "* lineare Regression,\n",
    "* naive Gaußsche Bayes-Klassifikation und\n",
    "* Gauß'sches Mixture-Model zum Clustering\n",
    "\n",
    "behandelt. Aber wie wählen wir eigentlich ein Modell für unsere Daten aus? Oft werden einfach viele verschiedene ML-Modelle durchprobiert und am Ende entscheidet man sich für das ML-Modell mit der besten Performance. Aber wie messen wir die Performance eines Modells? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1850961-c7ba-4f5a-b0b7-abcb56858cea",
   "metadata": {},
   "source": [
    "### Kreuzvalidierung\n",
    "\n",
    "Eine erste Idee dazu haben wir ebenfalls schon betrachtet. Wir halten einen Teil der Daten zurück, die sogenannten Testdaten, und trainieren das Modell nur mit den Trainingsdaten. Danach können wir ermitteln, wie gut das trainierte Modell die Testdaten prognostizieren kann. Diese Idee hat aber auch Schwächen, wie wir im folgenden Beispiel sehen.\n",
    "\n",
    "Nehmen Sie das Beispiel der Iris-Klassifikation. Führen Sie die nächste Code-Zelle fünfmal aus und notieren Sie sich den prozentualen Anteil der korrekt klassifizierten Irisblumen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bc36d8-c133-4dde-be8f-2e0a97b8acac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Module\n",
    "from sklearn import datasets\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Datenimport\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "# Auswahl des Modells mit Wahl der Hyperparameter (hier nur Standardwerte)\n",
    "model = GaussianNB()\n",
    "\n",
    "# Selektion Input und Output, Split in Trainings- und Testdaten\n",
    "X = iris['data']\n",
    "y = iris['target'] \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "# Training des ML-Modells\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Vergleich mit Messung \n",
    "y_predict = model.predict(X_test)\n",
    "\n",
    "correct = accuracy_score(y_test, y_predict)\n",
    "print('Es wurden {:.2f} % Irisblumen korrekt klassifiziert.'.format(correct*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02f9eb1-3399-4473-b311-b012e3e8e3fa",
   "metadata": {},
   "source": [
    "Sie werden feststellen, dass die Anzahl der korrekt klassifizierten Irisblumen schwankt. Das liegt daran, dass die Methode ``train_test_split()`` ca. 25 % der Daten als Testdaten zurückbehält und dabei *zufällig* auswählt, welche Daten in den Testdatensatz kommen. \n",
    "\n",
    "Mit zwei Optionen können wir die Aufteilung in Trainings- und Testdaten optional steuern:\n",
    "* ``test_size``: wird ein Integer angegeben, so entspricht dies der absoluten Anzahl der Testdatensätze; wird ein Float angegeben, so entspricht dies der relativen Anzahl an Testdatensätzen (0.0 entspricht 0 %, 1.0 entspricht 100 %).\n",
    "* ``random_state``: mit dieser Option kann ein Startwert (Integer) für die Generierung von Zufallszahlen gesetzt werden.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bb0647-250c-4386-aa21-caba7444b1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "X = iris['data']\n",
    "y = iris['target'] \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=None, random_state=None)\n",
    "\n",
    "number_of_test_data = np.shape(X_test)[0]\n",
    "number_of_all_data  = np.shape(X)[0]\n",
    "print('absolute Anzahl: {} Testdatensätze, prozentuale Anzahl {:.2f} %'.format(number_of_test_data, number_of_test_data/number_of_all_data * 100))\n",
    "\n",
    "print('Anfang von X_test: \\n', X_test[0:5, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f24d92e-cfee-469c-baa0-82915d37b669",
   "metadata": {},
   "source": [
    "Wenn wir einen Teil der Daten als Testdaten für die spätere Validierung zurückbehalten, hat das auch den Nachteil, dass wir weniger Datensätze für das Training haben. Und sollten wir ohnehin nur wenige Daten insgesamt haben, kann das zu Problem und ungenauen schlecht trainierten Modellen führen. Sinnvoll ist daher die **Kreuzvalidierung**.\n",
    "\n",
    "Die Idee der zweifachen Kreuzvalidierung ist wie folgt. Wir teilen die Daten in zwei Datensätze A und B und trainieren zweimal und testen dann auch zweimal. Um die Performance des Modells zu beurteilen, nehmen wir den Mittelwerte der beiden Tests.\n",
    "\n",
    "Die Idee der dreifachen Kreuzvalidierung ist, drei Durchläufe zu machen. Wir teilen die Daten in drei Datensätze A, B und C auf. Beim ersten Durchlauf trainieren wir mit A, B und testen mit C. Beim zweiten Durchlauf trainieren wir mit B,C und testen mit A. Und beim dritten Durchlauf findet das Training mit C,A statt und der Test mit B. Zuletzt bilden wir wieder den Mittelwert aus den drei Testwerten.\n",
    "\n",
    "Natürlich lässt sich diese Idee immer weiter treiben.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e1aa01-1f2c-4f65-992d-70e16022aff9",
   "metadata": {},
   "source": [
    "### Bestimmtheitsmaß $R^2$\n",
    "\n",
    "Das Bestimmtheitsmaß ist eine statistische Kennzahl, wie gut ein Modell zu den Daten (Messwerten) passt:\n",
    "* $R^2 = 1$ wäre perfekte Übereinstimmung,\n",
    "* $R^2 = 0$ heißt, das Modell ist nicht besser, als wenn man einfach den Mittelwert aus allen Daten bilden würde,\n",
    "* $R^2 < 0$ bedeutet ein schlechtes Modell.\n",
    "\n",
    "Details zur Berechnung des $R^2$-Scores finden Sie hier: https://de.wikipedia.org/wiki/Bestimmtheitsmaß . Wir verwenden in der Regel die in Scikit-Learn eingebauten Performance-Funktionen, so dass Sie sich die mathematischen Formeln nicht merken müssen. Details finden Sie hier: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html?highlight=r2#sklearn.metrics.r2_score . Ein Beispiel mit den Messwerten ``y_true``und den prognostizierten Werten ``y_pred``würde folgendermaßen ausgewertet werden:\n",
    "\n",
    "```code\n",
    "from sklearn.metrics import r2_score\n",
    "y_true = [3, -0.5, 2, 7]\n",
    "y_pred = [2.5, 0.0, 2, 8]\n",
    "r2_score(y_true, y_pred)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2feb7381-de32-4654-ac79-3156515f1b60",
   "metadata": {},
   "source": [
    "### Bias-Varianz-Dilemma oder Overfitting versus Underfitting\n",
    "\n",
    "Nachdem wir nun wissen, wie wir bestimmen können, ob wir ein gutes oder schlechtes Modell gewählt haben, schauen wir uns das **Bias-Varianz-Dilemma** an. Dazu folgendes Beispiel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4875c934-9def-4208-9530-70cbcb10fd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quelle: https://scipy-lectures.org/packages/scikit-learn/auto_examples/plot_bias_variance.html\n",
    "\n",
    "def generating_func(x, err=0.5):\n",
    "    return np.random.normal(10 - 1. / (x + 0.1), err)\n",
    "\n",
    "n_samples = 8\n",
    "\n",
    "np.random.seed(0)\n",
    "x = 10 ** np.linspace(-2, 0, n_samples)\n",
    "y = generating_func(x)\n",
    "\n",
    "x_test = np.linspace(-0.2, 1.2, 1000)\n",
    "\n",
    "titles = ['d = 1 (Underfitting; großer Bias)',\n",
    "          'd = 2',\n",
    "          'd = 6 (Overfitting; hohe Varianz)']\n",
    "degrees = [1, 2, 6]\n",
    "\n",
    "fig = plt.figure(figsize=(9, 3.5))\n",
    "fig.subplots_adjust(left=0.06, right=0.98, bottom=0.15, top=0.85, wspace=0.05)\n",
    "\n",
    "for i, d in enumerate(degrees):\n",
    "    ax = fig.add_subplot(131 + i, xticks=[], yticks=[])\n",
    "    ax.scatter(x, y, marker='x', c='k', s=50)\n",
    "\n",
    "    model = make_pipeline(PolynomialFeatures(d), LinearRegression())\n",
    "    model.fit(x[:, np.newaxis], y)\n",
    "    ax.plot(x_test, model.predict(x_test[:, np.newaxis]), '-b')\n",
    "\n",
    "    ax.set_xlim(-0.2, 1.2)\n",
    "    ax.set_ylim(0, 12)\n",
    "\n",
    "    ax.set_title(titles[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062b39ed-1bf9-40ac-875b-73f00758a562",
   "metadata": {},
   "source": [
    "Das linke Bild zeigt eine lineare Regression, aber offensichtlich sind die Daten nicht linear und die Gerade passt nicht besonders gut. Andererseits hat die lineare Funktion nur zwei Parameter, die trainiert werden müssen im Verhältnis zu 7 Datensätzen. Das mittlere ML-Modell scheint gut zu passen (3 Parameter zu 7 Datensätzen). Das rechte Bild zeigt ein Regressionspolynom vom Grad 6, das zu stark angepasst ist. Zwischen vorletztem und letztem Datenpunkt würde man ja einen Punkt dazwischen erwarten, aber das Regressionspolynom ist weit davon entfernt. Übrigens, 7 Parameter des Modells zu 7 Datensätzen... das konnte eigentlich gar nicht gut gehen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498141f8-9906-48fa-8514-7c48eaf24170",
   "metadata": {},
   "source": [
    "**Overfitting oder Überanpassung:** Mit Overfitting bezeichnen wir in Machine Learning ein Modell, das **zuviele** erklärende Variablen enthält. Das Modell erklärt nicht nur den Ursache-Wirkungszusammenhang, sondern sogar die Messfehler. Oder anders ausgedrückt, das Modell hat eine **große Varianz**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9591712-c98c-41c0-87e2-841f3ef8cc2a",
   "metadata": {},
   "source": [
    "**Underfitting oder Unteranpassung:** Das Modell ist nicht flexibel genug oder nicht komplex genug. Man kann auch sagen, es hat nicht genügend erklärende Variablen, um die Daten zu beschreiben. Oder anders ausgedrückt, das Modell hat ein **großes Bias** (eine große Verzerrung)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f382c0e-14ae-4987-8db0-e21e08760438",
   "metadata": {},
   "source": [
    "Wie können wir jetzt entscheiden, ob unser trainiertes Modell über- oder unterangepasst ist oder genau richtig?\n",
    "\n",
    "* Normalerweise sollte der Performance-Score der Trainingsdaten besser sein als der Score der Testdaten. Schließlich wurde das Modell ja mit den Trainingsdaten trainiert.\n",
    "* Wenn das Modell nicht komplex genug ist (Underfitting), ist der Performance-Score sowohl bei den Trainingsdaten als auch bei den Testdaten schlecht.\n",
    "* Ist das Modell überangepasst (Overfitting), dann ist der Performance-Score bei den Trainingsdaten super, aber schlecht bei den Testdaten.\n",
    "* Bei mittleren Modellen ist der Performance-Score bei den *Testdaten* besser als bei den unter- oder überangepassten Modellen.\n",
    "\n",
    "Die folgende Grafik (Quelle: Jake VanderPlas, Data Science mit Python, Abbildung 5.26) verdeutlicht diesen Zusammenhang noch einmal:\n",
    "\n",
    "![Validierungskurve](pics/fig10_validierungskurve.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f87387b-b176-4da9-bdda-d56bdb9595ea",
   "metadata": {},
   "source": [
    "# Übungsaufgaben zur Vertiefung"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ce860e-4050-4e7b-9a20-4ab64dce90ee",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\"><b>Aufgabe 10.1</b></br>\n",
    "Laden Sie den Datensatz ``bundesliga_top7_offensive.csv`` und filtern Sie die Daten nach Borussia Dortmund. \n",
    "\n",
    "* Führen Sie ein Clustering der Spieler nach Toren durch. Verwenden Sie 4 Cluster.\n",
    "* Schreiben Sie eine schöne Ausgabe, die die Namen der Fußballer eines jeden Clusters gemeinsam mit den Toren des Fußballers ausgibt.\n",
    "* Wie viele Fußballer sind gemeinsam mit Erling Haaland in einem Cluster?\n",
    "* Was passiert mit Marco Reus, wenn Sie die Anzahl der Cluster von 4 auf 3 Cluster reduzieren. Mit wem ist er jetzt in einem Cluster?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f42fe4-4206-4f5f-abfb-2c801c6788bc",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\"><b>Aufgabe 10.2</b></br>\n",
    "Laden Sie den Datensatz ``statistic_id224105_durchschnittlicher-dieselpreis-in-deutschland-bis-januar-2022.csv``. Dieser Datensatz enthält die wöchentlichen Dieselpreise vom Januar 2014 bis Januar 2022 (Quelle: https://de.statista.com/statistik/daten/studie/224105/umfrage/durchschnittlicher-preis-fuer-diesel-kraftstoff/ ) in Eurocent pro Liter.\n",
    "\n",
    "1. Trainieren Sie ein lineares Regressionsmodell für alle Dieselpreise seit Januar 2014 (Tipp: der erste Eintrag hat den Index '07. Jan 14'). Sie dürfen auf der x-Achse bzw. als Input die Anzahl der Wochen nehmen, also 1 bis 417. Lassen Sie den R2-Score berechnen, was vermuten Sie bzgl. Over- und Underfitting? Zeichnen Sie die Messwerte mit Punkten und plotten Sie die Gerade. Gutes oder schlechtes Modell?\n",
    "\n",
    "2. Wiederholen Sie Teilaufgabe 1 für ab dem Januar 2021 (Tipp: der Index lautet '5. Jan 21'). Vergleichen Sie Ihr Ergebnis mit dem Ergebnis für Teilaufgabe 1. \n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
