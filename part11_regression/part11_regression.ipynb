{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b94d91be-475b-43a4-af2a-f09c9f8308e6",
   "metadata": {},
   "source": [
    "# Regression\n",
    "\n",
    "Im vorletzten Kapitel haben wir uns mit der linearen Regression beschäftigt, im letzten Kapitel mit den Fragen\n",
    "* Wie wählen wir ein Modell aus?\n",
    "* Wie messen wir die Qualität bzw. Prognosegüte eines Modells, um das bestmögliche Modell mit optimalen Hyperparametern für unsere zu finden?\n",
    "* Was ist das Bias-Varianz-Dilemma (Underfitting vs. Overfitting)? \n",
    "\n",
    "In diesem Kapitel vertiefen wir die Fragestellungen weiter und diskutieren sie am Beispiel der **polynomialen Regression**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d97c8ca-d509-4b87-82a4-df56bd1d533d",
   "metadata": {},
   "source": [
    "## Wiederholung: lineare Regression\n",
    "\n",
    "In der Statistik versteht man unter **linearer Regression** ein Verfahren, bei dem es eine Einflussgröße $X$ und eine Zielgröße $y$ mit $N$ Paaren von dazugehörigen Messwerten $(x_1,y_1), (x_2,y_2), \\ldots, (x_N,y_n)$ gibt. Dann sollen zwei Koeffizienten $k_0$ und $k_1$ geschätzt werden, so dass $y_i = k_0 + k_1x_i$ gilt. Da bei den Messungen auch Messfehler passieren, werden wir die Gerade nicht perfekt treffen, sondern kleine Fehler machen, die wir hier mit $\\varepsilon_i$ bezeichnen. Wir suchen also $k_0$ und $k_1$, so dass   \n",
    "$$y_i = k_0 + k_1 x_i + \\varepsilon_i.$$\n",
    "\n",
    "Um uns jetzt für die weiteren Erläuterungen Spielbeispiele zur Verfügung zu haben, definieren wir uns eine Funktion, die künstlich Messdaten erzeugt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de90d680-f884-4fe9-878f-9c2ecafe63c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import default_rng\n",
    "\n",
    "def erzeuge_kuenstliche_messdaten(koeffizienten, anzahl_daten=50):\n",
    "    zufallszahlen_generator = default_rng(seed=42)\n",
    "    xmin = - 5.0\n",
    "    xmax = + 5.0\n",
    "    x = zufallszahlen_generator.uniform(xmin, xmax, anzahl_daten)\n",
    "\n",
    "    error = 3.0 * zufallszahlen_generator.standard_normal(anzahl_daten)\n",
    "    y = error\n",
    "    \n",
    "    for i in range(len(koeffizienten)):\n",
    "        y += koeffizienten[i] * x**i\n",
    "    return x.reshape(-1,1), y.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55d3f63-6b12-4e90-96f1-05601e4852bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "X,y = erzeuge_kuenstliche_messdaten([-3, 7], 20)\n",
    "X_original = np.linspace(-5, 5, 100)\n",
    "y_original = -3 + 7 * X_original\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(X, y)\n",
    "ax.plot(X_original, y_original, c='k', label='original')\n",
    "ax.legend();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc4efd6-38b3-4a82-b7db-7be0df71fb5f",
   "metadata": {},
   "source": [
    "**Mini_Übung**\n",
    "\n",
    "Teilen Sie den Datensatz in Trainings- und Testdaten auf. Trainieren Sie ein lineares Regressionsmodell mit Scikit-Learn. Bestimmen Sie den R2-Score von den Trainings- und den Testdaten. Visualisieren Sie Ihre Regressionsgerade zusammen mit den Messdaten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67182ea1-e415-4ce4-8cf0-2c9fa7251b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier Ihr Code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dfd5fc1-6dce-4a67-a8f9-8644c152f7b9",
   "metadata": {},
   "source": [
    "## Polynomiale Regression\n",
    "\n",
    "Wenn wir uns das folgende Beispiel betrachten, werden wir feststellen, dass die lineare Regression die Messdaten nicht besonders gut annähert. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd186c9-bcce-46ab-bd95-a18a4380b8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# erzeuge künstliche Daten\n",
    "X,y = erzeuge_kuenstliche_messdaten([-3, 7, 2, -2], 30)\n",
    "\n",
    "# Split in Trainings- und Testdaten\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y)\n",
    "\n",
    "# Auswahl des Modells \n",
    "model = LinearRegression()\n",
    "\n",
    "# Training \n",
    "model.fit(X_train, y_train)\n",
    "print('k0 = {}'.format(model.intercept_))\n",
    "print('k1 = {}'.format(model.coef_))\n",
    "\n",
    "# Validierung\n",
    "r2_train = r2_score(y_train, model.predict(X_train))\n",
    "r2_test  = r2_score(y_test,  model.predict(X_test))\n",
    "print('R2-Score der Trainingsdaten: {:.4}'.format(r2_train))\n",
    "print('R2-Score der Testdaten: {:.4}'.format(r2_test))\n",
    "\n",
    "# Visualisierung\n",
    "X_vis = np.linspace(-5,5,100).reshape(-1,1)\n",
    "y_vis = model.predict(X_vis)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,9))\n",
    "ax.scatter(X_train, y_train, label='train')\n",
    "ax.scatter(X_test, y_test, label='test')\n",
    "ax.plot(X_vis, y_vis, '--k')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f5bc70-c10d-4b04-b6cb-e44a7073b8a4",
   "metadata": {},
   "source": [
    "Der R2-Score ist sowohl bei den Trainingsdaten (0.7) als auch bei den Testdaten (0.6) nicht gut. Ein Regressionspolynom 2. oder 3. Grades könnte vielleicht besser passen. Wählen wir beispielsweise ein Polynom 3. Grades, so lautet das polynomiale Regressionsproblem wie folgt: Bestimme die Polynomkoeffizienten $k_0, k_1, k_2$ und $k_3$ so, dass\n",
    "$$y_i = k_0 + k_1\\cdot x_i + k_2\\cdot x_i^2 + k_3 \\cdot x_i^3 + \\varepsilon_i.$$ \n",
    "Wenn Sie in der Dokumentation von Scikit-Learn nun nach einer Funktion zur polynomialen Regression suchen, werden Sie nicht fündig werden. Tatsächlich brauchen wir auch keine eigenständige Funktion, sondern können uns mit einem Trick weiterhelfen. Wir erzeugen einfach eine zweite Spalte mit $x_i^2$ und eine dritte Spalte mit $x_i^3$ in den $N$ Zeilen von $i=1, \\ldots, N$. \n",
    "\n",
    "Dieser Trick wird auch bei anderen ML-Verfahren angewandt. Aus einem Input, aus einer Eigenschaft werden jetzt drei neue Eigenschaften gemacht. Aus einem eindimensionalen Input wird ein dreidimensionaler Input. Mathematisch gesehen haben wir die Input-Daten in einen höherdimensionalen Bereich projiziert. Diese Methode nennt man **Kernel-Trick**. Es ist auch möglich, andere Funktionen zu benutzen, um die Daten in einen höherdimensionalen Raum zu projizieren, z.B. radiale Gaußsche Basisfunktionen. Das nennt man dann **Kernel-Methoden**.  \n",
    "\n",
    "In dieser Vorlesung bleiben wir aber bei den Polynomen als Basisfunktion. Scikit-Learn stellt auch hier passende Methoden bereit.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6800e6-95d3-4a31-89e8-5aa6ccf969d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# erzeuge eine Matrix mit den Zahlen 1 bis 10 in der 1. Spalte\n",
    "X = np.arange(1,11).reshape(-1,1)\n",
    "print('Original X:\\n', X)\n",
    "\n",
    "# lade die Polynom-Transformator \n",
    "polynom_transformator = PolynomialFeatures(degree = 3)\n",
    "\n",
    "# transformiere X\n",
    "X_transformiert =  polynom_transformator.fit_transform(X)\n",
    "print('transformiertes X:\\n', X_transformiert)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727d918b-8f39-4568-9c1d-f852c902418a",
   "metadata": {},
   "source": [
    "Damit können wir nun verschiedene Regressionspolynome ausprobieren:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5bbcea-9851-4f04-afbf-5a36513cda21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# erzeuge künstliche Daten\n",
    "X,y = erzeuge_kuenstliche_messdaten([-3, 7, 2, -2], 30)\n",
    "\n",
    "# setze Polynomgrad\n",
    "grad = 3\n",
    "print('\\nGrad: {}'.format(grad))\n",
    "\n",
    "# Kernel-Trick, Split in Trainings- und Testdaten\n",
    "polynom_transformator = PolynomialFeatures(degree = grad)\n",
    "X = polynom_transformator.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y)\n",
    "\n",
    "# Auswahl des Modells \n",
    "model = LinearRegression()\n",
    "\n",
    "# Training \n",
    "model.fit(X_train, y_train)\n",
    "#print('k0 = {}'.format(model.intercept_))\n",
    "#print('k1 = {}'.format(model.coef_))\n",
    "\n",
    "# Validierung\n",
    "r2_train = r2_score(y_train, model.predict(X_train))\n",
    "r2_test  = r2_score(y_test,  model.predict(X_test))\n",
    "print('R2-Score der Trainingsdaten: {:.4}'.format(r2_train))\n",
    "print('R2-Score der Testdaten: {:.4}'.format(r2_test))\n",
    "\n",
    "# Visualisierung\n",
    "X_vis = polynom_transformator.fit_transform( np.linspace(-5,5,100).reshape(-1,1) )\n",
    "y_vis = model.predict(X_vis)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,9))\n",
    "ax.scatter(X_train[:,1], y_train, label='train')\n",
    "ax.scatter(X_test[:,1],   y_test, label='test')\n",
    "ax.plot(X_vis[:,1], y_vis, '--k')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a95fc1-5662-4caa-a39b-82e2316dd2e9",
   "metadata": {},
   "source": [
    "Das Transformieren der Daten in eine höhere Dimension machen den Code schwerer lesbar. Deswegen definieren wir nun hiier eine Funktion, die erst transformiert und dann das lineare Regressionsmodell anwendet. Der Grad des Polynoms wird dabei als Argument übergeben. Damit diese Funktion Transformation und lineare Regression hintereinander automatisch ausführen kann, benötigen wir von Scikit-Learn die sogenannte Pipieline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5a6d8a-50c0-488c-a8a2-467c40ffa9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "def PolynomialRegression(degree=2, **kwargs):\n",
    "    return make_pipeline(PolynomialFeatures(degree), LinearRegression(**kwargs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4afbfe76-32ef-4c10-b42d-835b32c611db",
   "metadata": {},
   "source": [
    "Damit kann der obige Code etwas kürzer geschrieben werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2659a1dc-c476-4532-8757-4cb45435036f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# erzeuge künstliche Daten\n",
    "X,y = erzeuge_kuenstliche_messdaten([-3, 7, 2, -2], 30)\n",
    "\n",
    "# setze Polynomgrad\n",
    "grad = 3\n",
    "print('\\nGrad: {}'.format(grad))\n",
    "\n",
    "# Split in Trainings- und Testdaten\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y)\n",
    "\n",
    "# Auswahl des Modells \n",
    "model = PolynomialRegression(degree = 3)\n",
    "\n",
    "# Training \n",
    "model.fit(X_train, y_train)\n",
    "#print('k0 = {}'.format(model.intercept_))\n",
    "#print('k1 = {}'.format(model.coef_))\n",
    "\n",
    "# Validierung\n",
    "r2_train = r2_score(y_train, model.predict(X_train))\n",
    "r2_test  = r2_score(y_test,  model.predict(X_test))\n",
    "print('R2-Score der Trainingsdaten: {:.4}'.format(r2_train))\n",
    "print('R2-Score der Testdaten: {:.4}'.format(r2_test))\n",
    "\n",
    "# Visualisierung\n",
    "X_vis = np.linspace(-5,5,100).reshape(-1,1) \n",
    "y_vis = model.predict(X_vis)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,9))\n",
    "ax.scatter(X_train, y_train, label='train')\n",
    "ax.scatter(X_test, y_test, label='test')\n",
    "ax.plot(X_vis, y_vis, '--k')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580df649-a7b5-4b6d-a5de-9268e50c2811",
   "metadata": {},
   "source": [
    "Als nächstes beschäftigen wir uns erneut mit der Frage, welches Modell am besten zu unseren Daten passt und ob Underfitting oder Overfitting vorliegt. Dazu kopieren wir den Code aus der obigen Code-Zelle und oacken ihn in eine for-Schleife:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1f75d2-7629-4253-88f0-bd3e293ee83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# erzeuge künstliche Daten\n",
    "X,y = erzeuge_kuenstliche_messdaten([-3, 7, 2, -2], 30)\n",
    "\n",
    "# Split in Trainings- und Testdaten\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y)\n",
    "\n",
    "# FOR-Schleife\n",
    "for grad in range(1,15):\n",
    "    print('\\nGrad: {}'.format(grad))\n",
    "\n",
    "\n",
    "    # Auswahl des Modells \n",
    "    model = PolynomialRegression(degree = grad)\n",
    "\n",
    "    # Training \n",
    "    model.fit(X_train, y_train)\n",
    "    #print('k0 = {}'.format(model.intercept_))\n",
    "    #print('k1 = {}'.format(model.coef_))\n",
    "\n",
    "    # Validierung\n",
    "    r2_train = r2_score(y_train, model.predict(X_train))\n",
    "    r2_test  = r2_score(y_test,  model.predict(X_test))\n",
    "    print('R2-Score der Trainingsdaten: {:.4}'.format(r2_train))\n",
    "    print('R2-Score der Testdaten: {:.4}'.format(r2_test))\n",
    "\n",
    "    # Visualisierung\n",
    "    X_vis = np.linspace(-5,5,100).reshape(-1,1) \n",
    "    y_vis = model.predict(X_vis)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12,9))\n",
    "    ax.scatter(X_train, y_train, label='train')\n",
    "    ax.scatter(X_test, y_test, label='test')\n",
    "    ax.plot(X_vis, y_vis, '--k')\n",
    "    ax.set_title('Grad: {}'.format(grad))\n",
    "    ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18457b1-5d38-4160-94a1-131235c4b1c4",
   "metadata": {},
   "source": [
    "Am besten notieren wir die verschiedenen R2-Scores mit, um zu entscheiden, ob Underfitting oder Overfitting vorliegt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9823f5e9-7e00-4b29-9446-d6a8916356df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# erzeuge künstliche Daten\n",
    "X,y = erzeuge_kuenstliche_messdaten([-3, 7, 2, -2], 30)\n",
    "\n",
    "# Split in Trainings- und Testdaten\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y)\n",
    "\n",
    "r2_train_liste = []\n",
    "r2_test_liste = []\n",
    "\n",
    "# FOR-Schleife\n",
    "for grad in range(1,15):\n",
    "    # Auswahl des Modells \n",
    "    model = PolynomialRegression(degree = grad)\n",
    "\n",
    "    # Training \n",
    "    model.fit(X_train, y_train)\n",
    "   \n",
    "    # Validierung\n",
    "    r2_train = r2_score(y_train, model.predict(X_train))\n",
    "    r2_test  = r2_score(y_test,  model.predict(X_test))\n",
    "   \n",
    "    r2_train_liste.append(r2_train)\n",
    "    r2_test_liste.append(r2_test)\n",
    "\n",
    "print(r2_train_liste)\n",
    "print(r2_test_liste)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e239f7-a6a3-4a8e-bc19-00ef4051b239",
   "metadata": {},
   "source": [
    "Ein Plot der R2-Scores hilft bei der Einschätzung Over-/Underfitting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2681cc-4259-452a-a7bb-93b37972ee93",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(range(1,15), r2_train_liste, label='train')\n",
    "ax.plot(range(1,15), r2_test_liste, label='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7ecfd3-ff82-4b43-a187-311a3784197d",
   "metadata": {},
   "source": [
    "Offensichtlich sind wir nach Grad 12 so schlecht, dass wir besser uns nur den Anfang angucken:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae978f3-fd41-4fed-9227-546a7057458f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "ax.plot(range(1,12), r2_train_liste[0:11], label='train')\n",
    "ax.plot(range(1,12), r2_test_liste[0:11], label='test')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bcb0e21-118e-4c5b-af12-9edc1def3276",
   "metadata": {},
   "source": [
    "Zwischen Grad 3 und Grad 8 ist der R2-Score für die Trainingsdaten praktisch gleich dem R2-Score der Testdaten. Diese Modelle können also gewählt werden. Für Grad 1 und 2 ist der R2-Score sowohl für Trainings- als auch Testdaten schlecht, es liegt Underfitting vor. Ab Grad 9 ist der R2-Score für die Trainingsdaten super, aber er fällt für die Testdaten ab. Wir sind im Bereich des Overfittings.\n",
    "\n",
    "Fazit: es kommen die polynomialen Regressionsmodelle für Grad 3 bis 8 infrage. Wenn man die Wahl hat, wählt man das einfachste Modell, also hier das mit Grad 3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5530223a-e860-46c3-addc-870b04e14993",
   "metadata": {},
   "source": [
    "# Übungsaufgaben zur Vertiefung"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc072c85-898c-4aea-85ff-df6a5d9e964f",
   "metadata": {},
   "source": [
    "#### Aufgabe 11.1\n",
    "\n",
    "Laden Sie den Datensatz ``data/population_germany.csv``. Wie viele Menschen werden in Deutschland im Jahr 2030 leben? Führen Sie eine vollständige Datenanalyse durch (Erkundung der Daten, Modellauswahl und Validierung inklusive Visualisierungen)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed782320-272b-44ee-91ca-04bff81f3926",
   "metadata": {},
   "source": [
    "#### Aufgabe 11.2\n",
    "\n",
    "Laden Sie den Datensatz ``data/population_india.csv``. Wie viele Menschen werden in Indien im Jahr 2030 leben? Führen Sie eine vollständige Datenanalyse durch (Erkundung der Daten, Modellauswahl und Validierung inklusive Visualisierungen). Geben Sie eine Einschätzung ab, wie gut ein Polynom die Bevölkerungsentwicklung in Indien abbildet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8989dc45-46fa-41bb-90ec-13b21cb40b5d",
   "metadata": {},
   "source": [
    "#### Aufgabe 11.3 (Wiederholung Python)\n",
    "\n",
    "Schreiben Sie ein Python-Programm für das Spiel Tic-Tac-Toe. Das Tic-Tac-Toe-Spiel soll folgendermaßen funktionieren:\n",
    "* Das Spielfeld ist ein 3x3-Feld. Tipp: lässt sich beispielsweise durch ein 2d-Array realisieren.\n",
    "* Zwei Spieler wählen abwechselnd ein Feld und markieren das gewählte Feld mit ihrem Zeichen (entweder X oder O). Tipp: lässt isch beispielsweise durch -1 oder +1 besser verarbeiten.\n",
    "* Der erste Spieler, der eine komplette Zeile oder eine komplette Spalte oder eine komplette Diagonale mit seinem Zeichen gefüllt hat, gewinnt.\n",
    "* Der Computer fragt nach den Spielereingaben und stellt das Feld mit dem aktuellen Spielstand dar. Sobald einer der Spieler gewonnen hat, gibt der Computer dies aus; ansonsten meldet der Computer \"Unentschieden!\".\n",
    "\n",
    "Optional können Sie anstatt der Eingaben eines zweiten Spielers auch den Computer zufällig Felder wählen lassen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acdc6d8f-981f-4cb1-910f-7acfac9a10c1",
   "metadata": {},
   "source": [
    "#### Aufgabe 11.4 (Wiederholung Datentypen)\n",
    "\n",
    "Gehen Sie alle bisherigen Jupyter Notebooks durch und notieren Sie hier die in der Vorlesung behandelten Datentypen:\n",
    "\n",
    "* XXX\n",
    "* XXX\n",
    "* XXX\n",
    "...\n",
    "\n",
    "Was ist überhaupt ein Datentyp? Geben Sie für jeden Datentyp ein Beispiel an."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
