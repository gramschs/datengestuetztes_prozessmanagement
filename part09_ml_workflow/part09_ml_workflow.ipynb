{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "999691b9-65e0-4862-9595-1e89de810074",
   "metadata": {},
   "source": [
    "# Maschinelles Lernen - Einführung und genereller Ablauf eines ML-Projektes\n",
    "\n",
    "Bereits 1959 hat Arthur L. Samuel eine Beschreibung abgegeben, was maschinelles Lernen (ML) ist. Er sagte\n",
    "> Maschinelles Lernen ist ein Forschungsgebiet, das Computer in die Lage versetzen soll, zu lernen, ohne explizit darauf programmiert zu sein.\n",
    "\n",
    "Aber was genau soll der Computer lernen? Und wie bringen wir einem Computer bei, etwas zu lernen? \n",
    "\n",
    "In dieser Vorlesung fokussieren wir uns auf das maschinelle Lernen im Bereich des datengestützten Prozessmanagements. Dabei werden wir naturwissenschaftliche, ingenieurwissenschaftliche, betriebswirtschaftliche und gesellschaftliche Prozesse betrachten. Wenn der Computer etwas aus diesem Bereich lernt, ist damit gemeint, dass der Computer ein Modell bzw. eine mathematische Funktion aufstellt. Der einfachste Ablauf eines ML-Projektes sieht dabei wie folgt aus:\n",
    "\n",
    "![Ablauf datengestüztes Prozessmanagement](pics/fig09_datengestuetztes_prozessmanagement.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4afc48ce-b376-4cea-8593-ec21dfb51525",
   "metadata": {},
   "source": [
    "## Beispiel eines einfachen ML-Projektes für CO2-Emissionen \n",
    "\n",
    "**Frage: Wie hoch werden voraussichtlich die weltweiten CO2-Emissionen im Jahr 2030 sein?**\n",
    "\n",
    "Als erstes beschaffen wir uns Daten zu den bisherigen Emissionen. Beispielsweise finden Sie unter https://de.statista.com/statistik/daten/studie/37187/umfrage/der-weltweite-co2-ausstoss-seit-1751/#professional die CO2-Emissionen weltweit in den Jahren 1960 bis 2020 gemessen in Millionen Tonnen.\n",
    "\n",
    "Nachdem wir also passende Daten gesammelt haben, erkunden wir sie. Zuerst lesen wir die Daten ein und verschaffen uns einen groben Überblick über die statistischen Kennwerte und Trends per Visualisierung."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8691ff-14aa-4e6f-b1fc-d142ae7e97f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('data/statistic_id37187_co2-ausstoss-weltweit-bis-2020.csv', skiprows=3, index_col=0)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa9c590-7567-46f6-a00c-cdb14e6cd2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb4c8d8-63cd-43d3-8c08-6d84e0886e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0dbe3a-5c4c-4681-9d4d-376fd2751db2",
   "metadata": {},
   "source": [
    "Sieht (leider) nach einem Muster aus. Das Muster müssen wir für den Computer als ein Modell bzw. als eine Funktion beschreiben. Probieren wir es mit dem einfachsten Modell, der linearen Funktion. \n",
    "\n",
    "Eine lineare Funktion hat zwei Parameter:\n",
    "* Steigung $m$ und\n",
    "* y-Achsenabschnitt $b$,\n",
    "also insgesamt die Funktionsgleichung $y = mx + b$. Dabei ist $x$ die Variable oder der Input und $y$ ist der Funktionswert oder der Output. \n",
    "\n",
    "**Mini-Übung:**   \n",
    "\n",
    "Probieren Sie verschiedene Parameter $m$ und $b$ für das lineare Modell $y = mx+b$ aus, bis die Gerade möglichst gut zu den CO2-Emissionsdaten passt. Zeichen Sie zur Überprüfung die Gerade (mit rot) und die Emissionsdaten in einen gemeinsamen Plot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9664528c-16c4-4d5c-8efc-410327404d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier Ihr Code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd613bce-495a-482b-b614-9c506b626041",
   "metadata": {},
   "source": [
    "Jetzt können wir eine Prognose formulieren, wie viel CO2 voraussichtlich 2030 ausgestoßen wird, wenn sich am jetzigen Muster nichts ändert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98518bc-4890-4f4b-978d-f97cb7e719b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier Ihr Code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2ef95d-cc98-4f7d-96a9-5bffb0415081",
   "metadata": {},
   "source": [
    "**Antwort: Im Jahr 2030 werden voraussichtlich 41271 Millionen Tonnen CO2 ausgestoßen werden.**\n",
    "\n",
    "Damit hat man die ursprünglich gestellte Frage beantwort. Oft führt das Erkunden der Daten aber dazu, dass man beginnt neue Fragen zu stellen. Beispielsweise:\n",
    "* Was war denn im Jahr 2020?\n",
    "* Hat sich der Anstieg von 2010 bis 2020 verlangsamt? Beispielsweise im Vergleich zu den Jahren 2000 bis 2010?\n",
    "\n",
    "Das sind alles Fragen, die die Daten oder den Prozess selbst betreffen. Dazu kommen noch die Fragen an den ML-Workflow selbst, aber mehr dazu später."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b813acf-dd33-4ca5-b0cc-ab511cadbe11",
   "metadata": {},
   "source": [
    "## Grundlegende Begriffe des maschinellen Lernens\n",
    "\n",
    "Wie Samuel bereits 1959 formuliert hat, ist \"...maschinelles Lernen (ML) ein Forschungsgebiet, das Computer in die Lage versetzen soll, zu lernen, ohne explizit darauf programmiert zu sein.\" Konkret lernt der Computer aufgrund von Daten, wie die Parameter eines mathematischen Modells einzustellen sind. In unserem Beispiel mit den CO2-Emissionen haben wir als Modell eine lineare Funktion $y = mx + b$ verwendet, die zwei Parameter hat (Steigung $m$ und y-Achsenabschnitt $b$).  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da58d1ee-f300-4543-ab1e-4098f21f3ae9",
   "metadata": {},
   "source": [
    "### Kategorien des maschinellen Lernens\n",
    "\n",
    "Es gibt viele verschiedene Lernverfahren in der Praxis. Konkret werden die Lernverfahren durch Algorithmen umgesetzt. Diese Algorithmen wiederum lassen sich grob in die zwei folgenden Kategorien aufteilen:\n",
    "1. überwachtes Lernen (supervised learning)\n",
    "2. unüberwachtes Lernen (unsupervised learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86729352-a22e-4077-bd37-c8f370727fcf",
   "metadata": {},
   "source": [
    "#### Überwachtes Lernen (Supervised Learning)\n",
    "\n",
    "Beim überwachten Lernen gehören zu den Daten **Eingabedaten (Input)** und **Ausgabedaten (Output)**. Ziel des überwachten Lernens ist dann, ein mathematisches Modell zu lernen, das die Eingabedaten auf die Ausgabedaten abbildet. In unserem Beispiel waren die Jahre die Eingabedaten und die CO2-Emissionen die Ausgabedaten.\n",
    "\n",
    "Häufig werden die Eingabedaten auch als **Eigenschaft**, **Merkmal**, **Attribut** oder **Feature** bezeichnet, während die Ausgabedaten oft mit **Klassenbezeichnung**, **Kategorie**, **Label**, **Target** oder **Zielwert** bezeichnet werden. Wir haben also folgende Begriffe:\n",
    "\n",
    "* Eingabedaten: $x$, $X$, Input, Eigenschaft, Merkmal, Feature oder Attribut\n",
    "* Ausgabedaten: $y$, Output, Klassenbezeichnung, Kategorie, Label, Target, Zielwert\n",
    "\n",
    "Beim überwachten Lernen wird zusätzlich noch unterschieden, ob der Output stetig/kontinuierlich oder diskret/diskontinuierlich vorliegt. Falls der Output aus stetigen Werten besteht, spricht man von **Regression**. Sollen jedoch diskrete Kategorien prognostiziert werden, spricht man von **Klassifikation**. Die englischen Begriffe dafür sind **regression** und **classification**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20945234-1bca-4e62-8d50-97227aad6e51",
   "metadata": {},
   "source": [
    "**Mini-Übung**\n",
    "\n",
    "Schauen Sie das Video https://www.youtube.com/watch?v=NCCctUdfA3E&list=PLzdtN2eQTAhkXUvlIFciv7RxLneTpD6H9&index=6 zum Thema \"So lernen Maschinen: Überwachtes Lernen - Regression\" (4:11 min). Beantworten Sie folgende Fragen:\n",
    "* Was ist in dem Eiskugel-Beispiel der Input?\n",
    "* Was ist in dem Eiskugel-Beispiel der Output?\n",
    "* Welche zwei zusätzlichen Eigenschaften schlägt Fabrizio vor, um das Eiskugel-Verkaufsmodell besser zu machen?\n",
    "* Welche weiteren Eigenschaften könnten Ihrer Meinung nach noch dazugenommen werden, um das Modell besser zu machen? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c24db55-a765-451f-8435-d8811b59e298",
   "metadata": {},
   "source": [
    "# Hier Ihr Antworten\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ba8505-fdf2-4c09-a4f3-d3d054a1b59f",
   "metadata": {},
   "source": [
    "**Mini-Übung**\n",
    "\n",
    "Schauen Sie das Video https://www.youtube.com/watch?v=g6zuVEDlAzo&list=PLzdtN2eQTAhkXUvlIFciv7RxLneTpD6H9&index=5 zum Thema \"So lernen Maschinen: Überwachtes Lernen - Klassifikation\" (4:25 min). Beantworten Sie folgende Fragen:\n",
    "\n",
    "* Welches sind die beiden Inputs des Skulpturen-Beispiels? \n",
    "* Wie viele verschiedene Klassen gibt es für den Output? Wie heißen sie? \n",
    "* Wo ist der grüne Bereich für die Skulpturen? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b8b0f1-093a-461b-babb-e40dff47c4f5",
   "metadata": {},
   "source": [
    "# Hier Ihre Antworten\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4edfb5fe-5198-4b81-8799-b79efed451f0",
   "metadata": {},
   "source": [
    "### Unüberwachtes Lernen (Unsupervised Learning)\n",
    "\n",
    "Beim unüberwachten Lernen gibt es nur Eingabedaten. Es gibt keinen Trainer, der vorgibt, zu welcher Kategorie ein Datensatz gehört. Stattdessen erkennen Algorithmen selbst, dass bestimmte Eingabedaten zu einer Kategorie und andere Eingabedaten zu einer anderen Kategorie gehören. Das Einteilen in verschiedene Kategorien oder Klassen nennt man **Clustering**. Eine weitere Anwendung des unüberwachten Lernens ist, eine einfachere Beschreibung der Daten zu finden. Das nennt man **Dimensionsreduktion** bzw. im Englischen **dimensionality reduction**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b634fe-2b5b-4f48-9f63-d9c1d6f71338",
   "metadata": {},
   "source": [
    "**Mini-Übung**\n",
    "\n",
    "Schauen Sie das Video https://www.youtube.com/watch?v=P2Qwc63iCVQ&list=PLzdtN2eQTAhkXUvlIFciv7RxLneTpD6H9&index=4 zum Thema \"So lernen Maschinen: Unüberwachtes Lernen\" (5:19 min). Beantworten Sie folgende Fragen:\n",
    "\n",
    "* Wie viele Input-Größen gibt es beim Betrüger-Beispiel? Wie heißen die Eigenschaften? \n",
    "* Was ist in dem Betrüger-Beispiel der Output? \n",
    "* Handelt das Video von Clustering oder Dimensionsreduktion?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95fe37e-e2e1-4f5a-a17e-931ac837a44a",
   "metadata": {},
   "source": [
    "# Hier Ihre Antworten\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f14104-2e56-457f-90aa-8fe5b49b0b8a",
   "metadata": {},
   "source": [
    "## Beispiele mit Scikit-Learn\n",
    "\n",
    "Gute Nachricht vorneweg: Sie müssen die Algorithen nicht selbst implementieren, das haben bereits Wissenschaftler:innen aus der Mathematik und der Informatik erledigt. Eine der bekanntesten Bibliotheken bzw. eines der bekanntesten Module ist Scikit-Learn, siehe https://scikit-learn.org/stable/, das wir auch für diese Vorlesung verwenden werden. Bitte stellen Sie jetzt sicher, dass Scikit-Learn bei Ihnen installiert ist. \n",
    "\n",
    "Das Module Scikit-Learn wird mit ``sklearn`` abgekürzt, alle Funktionen würden also z.B. mit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bf2d43-732d-4669-830d-1fe7d082b5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c8b00a-f560-4da5-a01b-4e5569f76df2",
   "metadata": {},
   "source": [
    "geladen werden. Da das Modul aber so mächtig ist, werden wir immer nur einzelne Funktionen aus Scikit-Learn importieren. \n",
    "\n",
    "### Grundlegender ML-Workflow mit Scikit-Learn \n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<ol>\n",
    "<li>Zuerst wählen wir ein Modell aus, das trainiert werden soll. </li>\n",
    "<li>Danach wählen wir die Hyperparameter des Modells aus. Hyperparameter sind Parameter des Modells, die wir vorab ohne Kenntnis der Daten festlegen.</li>\n",
    "<li>Danach packen wir die Inputdaten in eine Matrix X, bei der jede Spalte eine Eigenschaft repräsentiert und in den Zeilen die Daten stehen.</li>\n",
    "<li>Falls wir ein überwachtes Lernverfahren anwenden wollen, packen wir die Outputdaten in einen Zeilenvektor y.</li>\n",
    "<li>Wir trainieren das ML-Modell, indem wir die fit()-Methode aufrufen.</li>\n",
    "<li>Um das Modell zur Prognose neuer Daten zu verwenden, benutzten wir die predict()-Methode</li>\n",
    "</ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538e96c4-968c-4a77-a8ef-17d0561acc9a",
   "metadata": {},
   "source": [
    "#### Einfache lineare Regression mit Scikit-Learn\n",
    "\n",
    "Zuerst laden wir die Daten ein. Wir nehmen hier erneut das Beispiel mit den CO2-Emissionen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0c323c-3a2c-441a-b611-bd6922f87bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('data/statistic_id37187_co2-ausstoss-weltweit-bis-2020.csv', skiprows=3, index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0dc4a46-eba7-4e94-a117-0688aef1c849",
   "metadata": {},
   "source": [
    "Normalerweise würden wir uns nun einen Überblick über die Daten erschaffen, aber das haben wir ja schon erledigt. Die Ausgabedaten sind kontinuierliche Zahlen, also liegt überwachtes Lernen mit Regression vor. Wir schauen bei Scikit-Learn nach, welche Algorithmwn für Regression schon implementiert wurden, siehe\n",
    "\n",
    "> https://scikit-learn.org/stable/supervised_learning.html#supervised-learning\n",
    "\n",
    "Das einfachste Modell ist das lineare Regressionsmodell \"Ordinary Least-Squares\". Wir schauen uns an, welche Parameter es hat. \n",
    "\n",
    "> https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression\n",
    "\n",
    "Die folgenden fünf Parameter werden in der Dokumentation beschrieben:\n",
    "\n",
    "* fit_intercept \n",
    "* normalize \n",
    "* copy_X \n",
    "* n_jobs \n",
    "* positive \n",
    "\n",
    "Scikit-Learn hat den Vorteil, dass die Standardeinstellungen bereits sehr gut gewählt sind. Im Zweifelsfall  wählt man also das Modell mit seinen Standardwerten. Vorher muss es noch importiert werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5e2350-e2d3-4576-a0a7-08156d1770a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import des Modells\n",
    "from sklearn.linear_model import LinearRegression \n",
    "\n",
    "# Auswahl mit Standardeinstellungen\n",
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d344e5ff-4cf7-4fd6-9cec-a2b5a7ae6b6c",
   "metadata": {},
   "source": [
    "Als nächstes packen wir die Inputdaten in eine Matrix X (also ein NumPy-Array), bei der in der ersten Spalte das Jahr steht (weitere Spalten gibt es hier nicht). Das Jahr steht in dem pandas-DataFrame im Index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26cd31e-6b47-4eae-afd4-6b7e46037523",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.index.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd74b7cd-97d4-4f6e-9672-9201c8cca34a",
   "metadata": {},
   "source": [
    "Überprüfen wir, ob das geklappt hat. Zuerst geben wir den Inhalt von X aus, dann kontrollieren wir die Dimension der Matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13acef11-1854-4860-95a3-ccbe1e1a9242",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X)\n",
    "print(np.shape(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71cf176b-2fb9-444b-a05b-ebe3fbc84442",
   "metadata": {},
   "source": [
    "Leider haben wir keine Matrix, sondern einen Spaltenvektor (1D-Array) erhalten. Wir müssen X noch in eine Matrix mit 21 Zeilen und 1 Spalte umwandeln."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ea2f96-7338-4cad-8b00-120a109ef211",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.reshape(21,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4e1842-de38-4041-b935-ebba7ad7e769",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.reshape(21,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d9f9bf-03cb-49e8-b628-99f37f13e83f",
   "metadata": {},
   "source": [
    "Nun packen wir den Output in einen Spaltenvektor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b956a2-e766-462e-8fa5-5db7b597814f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data.loc[:, 'CO2-Emission'].values # y = data.values waere auch gegangen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf40e23-8e68-46db-9180-a21224679751",
   "metadata": {},
   "source": [
    "Überprüfen wir wieder Inhalt und Dimension:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ff2ef9-8499-4dc1-bcbc-c15129cd346c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y)\n",
    "print(np.shape(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b8f389-0595-480b-a58a-a24fe042f6f2",
   "metadata": {},
   "source": [
    "Diesmal müssen wir y nicht ändern, ein Spaltenvektor ist genau das, as wir brauchen. Nun trainieren wir das Modell, indem wir die ``fit()``-Methode aufrufen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b738a6-f79b-4c52-b0f1-7911ca3b70bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0ded62-aa40-4932-8b84-f4499ff48b00",
   "metadata": {},
   "source": [
    "Nachdem das Modell trainiert wurde, sieht man zunächst nichts. Doch im Hintergrund wurden für dieses Modell nun die gelernten Modellparameter im Modell selbst mit abgespeichert. Welche Modellparameter es gibt, zeigt wiederum die Dokumentation\n",
    "\n",
    "> https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression\n",
    "\n",
    "im Abschnitt Attribute. Um die Modellparameter, die au den Daten gelernt werden, von den zu Beginn der Wahl festgelegten Modellparametern (= Hyperparametern) besser zu unterscheiden, werden die datenbasierten Modellparamater mit einem **Unterstrich** gekennzeichnet. Wir finden in der Dokumentation für das lineare Regressionsmodell mit Least-Sqaures folgende datenabhängige Modellparameter:\n",
    "\n",
    "* coef_ \n",
    "* rank_\n",
    "* singular_ \n",
    "* intercept_\n",
    "* n_features_in_\n",
    "* feature_names_in_\n",
    "\n",
    "In ``coef_`` wird die Steigung gespeichert, in ``intercept_`` der y-Achsenabschnitt. Lassen wir uns beides ausgeben:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43550b2c-7bb8-4d2a-aab3-3996cd709d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Steigung: ', model.coef_)\n",
    "print('y-Achsenabschnitt: ', model.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ba5893-a659-4251-aadd-f32246e38c4c",
   "metadata": {},
   "source": [
    "Zuletzt können wir dieses Modell nun zu einer Prognose benutzen und für neue Daten auswerten. Wir werten nun das trainierte Modell für 1960 bis 2030 aus. Damit können wir zum einen mit den echten Daten bis 2020 vergleichen, zum anderen einen Blick in die Zukunft werfen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6081b1d4-931d-45e0-b83b-e4b42af90d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_prediction = np.linspace(1960, 2030).reshape(-1,1)\n",
    "y_prediction = model.predict(X_prediction)\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(X, y, 'o')\n",
    "ax.plot(X_prediction, y_prediction, '-');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abe9b4c-ca0b-43cd-b48f-e450e52b8be2",
   "metadata": {},
   "source": [
    "Hinweis: wir werden öfters aus einem 1d-Array ein 2d-Array machen. Dazu bietet sich die Kurzform ``.reshape(-1,1)`` an.\n",
    "\n",
    "Und jetzt noch einmal alles zusammen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0a360e-dbaa-4ba3-ac12-ff4b694bf1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "# Datenimport\n",
    "data = pd.read_csv('data/statistic_id37187_co2-ausstoss-weltweit-bis-2020.csv', skiprows=3, index_col=0)\n",
    "\n",
    "# Auswahl des Modells mit Wahl der Hyperparameter (hier nur Standardwerte)\n",
    "model = LinearRegression()\n",
    "\n",
    "# Selektion Input und Output im richtigen Format\n",
    "X = data.index.values.reshape(-1,1)\n",
    "y = data.values\n",
    "\n",
    "# Training des ML-Modells\n",
    "model.fit(X, y)\n",
    "\n",
    "# Vergleich mit Messung und Prognose für die Zukunft\n",
    "X_predict = np.linspace(1960, 2030).reshape(-1,1)\n",
    "y_predict = model.predict(X_predict)\n",
    "\n",
    "# Visualisierung\n",
    "fig, ax = plt.subplots(figsize=(16,9))\n",
    "ax.plot(X,y, 'o', label='Messung')\n",
    "ax.plot(X_predict,y_predict, '-', label='Modell')\n",
    "ax.set_xlabel('Jahr')\n",
    "ax.set_ylabel('CO2-Emission')\n",
    "ax.legend()\n",
    "ax.set_title('Training eines linearen Regressionsmodells für CO2-Emissionen');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401f03f7-0e09-4ede-9611-dac9a74d42ae",
   "metadata": {},
   "source": [
    "### Einfache Klassifikation mit Scikit-Learn\n",
    "\n",
    "Um an einem einfachen Beispiel die Vorgehensweise für Klassifikationsaufgaben vorzustellen, verwenden wir ein sehr bekanntes Beispiel aus dem maschinellen Lernen, die Klassifikation von Irisblumen. Der Iris-Datensatz wird bereits seit 1936 genutzt, um Klassifikationsverfahren zu testen, siehe https://en.wikipedia.org/wiki/Iris_flower_data_set. In dem Datensatz sind drei verschiedene Irisarten:\n",
    "\n",
    "Iris setosa | Iris versicolor | Iris virginica\n",
    "- | - | -\n",
    "<img src=\"pics/fig09_iris_setosa.jpg\" alt=\"Iris setosa\" style=\"width: 200px;\"/> | <img src=\"pics/fig09_iris_versicolor.jpg\" alt=\"Iris versicolor\" style=\"width: 200px;\"/> | <img src=\"pics/fig09_iris_virginica.jpg\" alt=\"Iris vriginica\" style=\"width: 200px;\"/>\n",
    "\n",
    "Quelle linkes Bild: CC BY-SA 3.0, https://commons.wikimedia.org/w/index.php?curid=170298, ansonsten lizenzfrei\n",
    "\n",
    "Für jede dieser drei Arten gibt es 50 Beispiele, bei denen vier Eigenschaften erfasst sind:\n",
    "\n",
    "* sepal_length: Länge des Kelchblatts in cm\n",
    "* sepal_width: Breite des Kelchblatts in cm\n",
    "* petal_length: Länge des Kronblatts in cm\n",
    "* petal_width: Breite des Kronblatts in cm\n",
    "\n",
    "Da dieses Beispiel so häufig verwendet wird, ist es sogar in Scikit-Learn hinterlegt und die Iris-Daten können direkt geladen werden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8637ccd-aaea-42b7-9fd1-a7fd19ecf662",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "iris"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8e6728-1b59-4eb3-b4f0-63672767767a",
   "metadata": {},
   "source": [
    "Nach dem Laden des Iris-Datensatzes stellen wir fest, dass die Variable `iris` nun ein Dictionary enthält. Wir können also mit eckigen Klammern auf die einzelnen Bestandteile des Datensatzes zugreifen. In `data` stehen die Eingabedaten, in `target`die Ausgabedaten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a72428-63a3-440f-98bc-2b046fa48b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris['data']\n",
    "print('Dimension von X: ', np.shape(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a822ba99-5f3b-4884-aac5-7fc753845783",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = iris['target']\n",
    "print('Dimension von y: ', np.shape(y)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4a06a9-e86c-46b1-945b-18030ee15bee",
   "metadata": {},
   "source": [
    "Wenn wir uns den Inhalt von `y` betrachten, stellen wir fest, dass dort nicht etwa 'setosa', 'versicolor' oder 'virginica' steht, sondern nur 0, 1 oder 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b27fe2b-58d0-4069-a768-4dc5ddbb4bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149ebe8b-9c3b-42ee-8851-de9ab05c6707",
   "metadata": {},
   "source": [
    "Für die mathematischen ML-Algorithmen müssen wir die Kategorien, d.h. in diesem Fall die drei Iris-Arten, codieren. Damit ist gemeint, dass jede Kategorie einen Zahlencode bekommt. Hier steht also die 0 für Iris setosa, 1 für Iris versicolor und 2 für Iris virginica.\n",
    "\n",
    "Erkunden wir zunächst die Daten. Wir nehmen immer zwei Eigenschaften und stellen die Iris-Art über die Farbe dar, Scatterplots!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fa7c8f-cb15-44d8-bab7-95590774db3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(X[:, 0], X[:, 1], c=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52b0e3b-4104-441e-b0a2-cc26d18ccdfe",
   "metadata": {},
   "source": [
    "Da es mühsam ist, alle Kombinationen von Hand zu bilden, lassen wir das Python machen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d670daf3-e285-486c-89f1-71d736eccff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "merkmale = ['Länge Kelchblatt (cm)', 'Breite Kelchblatt (cm)', 'Länge Kronblatt (cm)', 'Breite Kronblatt (cm)']\n",
    "\n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.scatter( X[:,i], X[:,j], c=y )\n",
    "        ax.set_xlabel(merkmale[i])\n",
    "        ax.set_ylabel(merkmale[j])\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe4c0df-e8f1-44af-8979-63228a11dfe0",
   "metadata": {},
   "source": [
    "Als nächstes wählen wir ein Modell mit Hyperparametern und trainieren es. Diesmal wird es aber schwierig zu testen, ob das trainierte Modell gute Prognosen liefert. Daher legen wir von Anfang einige der Datensätze zur Seite. Diese Daten nennen wir **Testdaten**. Mit den übriggebliebenen Daten trainieren wir das ML-Modell. Diese Daten nennen wir **Trainingsdaten**. Später nutzen wir dann die Testdaten, um zu überprüfen, wie gut das Modell funktioniert.\n",
    "\n",
    "Für die Aufteilung in Trainings- und Testdaten nehmen wir eine maßgeschneiderte Funktion von Scikit-Learn namens `train_test_split`, siehe auch https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79354fea-e7a7-4ec1-a550-ca4572db94d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "print('Dimension X_train: ', np.shape(X_train))\n",
    "print('Dimension X_test: ',  np.shape(X_test))\n",
    "print('Dimension y_train: ', np.shape(y_train))\n",
    "print('Dimension y_test: ',  np.shape(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b121df-2270-450a-b10b-bd0784ae70d0",
   "metadata": {},
   "source": [
    "Jetzt können wir ein ML-Modell wählen. Eines der einfachsten Klassifikationsmodelle ist das Gaußsche naive Bayes Modell, auch wenn der Name überhaupt nicht einfach ist. \n",
    "> https://scikit-learn.org/stable/modules/naive_bayes.html\n",
    "\n",
    "Dafür hat es gar keine Hyperparameter und kann direkt eingesetzt werden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3566c5ce-afd1-4e71-9d4a-503e78f17321",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "model = GaussianNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0d2b59-1cfb-4301-bdb1-68300a2bd92f",
   "metadata": {},
   "source": [
    "Jetzt das Training mit den Trainingsdaten (!):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546409f0-9706-434a-8530-1c5e301a3e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f74022c-8384-4d91-8bb3-eda994536478",
   "metadata": {},
   "source": [
    "Nun können wir testen, wie gut das Training funktioniert hat, indem wir mit dem ML-Modell prognostizieren, welche Iris-Art es für die Testdaten voraussagen würde:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c778ab9-914d-4903-8651-bc510e938723",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ceaaef5-d3c4-4303-850d-c215b055d4f6",
   "metadata": {},
   "source": [
    "Sehen wir uns mal die Vorhersage `y_predict` und die tatsächlichen Daten `y_test` an, die wir ja zuvor beiseite gelegt hatten:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f454669-8b6d-4f8a-9504-5d467c9085e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_predict)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160c67ac-c73f-4859-9f1f-6625eca1d59e",
   "metadata": {},
   "source": [
    "Sieht eigentlich ganz gut aus, doch an der 26. Stelle liegt unser Modell falsch. Überhaupt, das Vergleichen ist händisch etwas mühsam. Aber uach hier hilft Scikit-Learn, das eine Funktion zur Verfügung stellt, die den Anteil der korrekt prognostizierten Werte berechnet, nämlich `accuracy_score()`, siehe auch\n",
    "> https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d84f37e-45b4-4b4a-8f05-dc929ee300ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "correct = accuracy_score(y_test, y_predict)\n",
    "print('Es wurden {:.2f} % Irisblumen korrekt klassifiziert.'.format(correct*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1918d0db-9d3c-405d-a4fd-fb3e7f777bce",
   "metadata": {},
   "source": [
    "Und hier noch einmal alles zusammen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea642bc6-aa46-4727-bdbc-4595f6f089d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Module\n",
    "from sklearn import datasets\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Datenimport\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "# Auswahl des Modells mit Wahl der Hyperparameter (hier nur Standardwerte)\n",
    "model = GaussianNB()\n",
    "\n",
    "# Selektion Input und Output, Split in Trainings- und Testdaten\n",
    "X = iris['data']\n",
    "y = iris['target'] \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "# Training des ML-Modells\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Vergleich mit Messung \n",
    "y_predict = model.predict(X_test)\n",
    "\n",
    "correct = accuracy_score(y_test, y_predict)\n",
    "print('Es wurden {:.2f} % Irisblumen korrekt klassifiziert.'.format(correct*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613a6a05-6901-48d6-adba-552f7c639ba2",
   "metadata": {},
   "source": [
    "### Einfaches Clustering mit Scikit-Learn\n",
    "\n",
    "Wir verwenden für das nächste Beispiel den Iris-Datensatz weiter. Angenommen, wir wüssten nicht, dass es sich um drei Iris-Arten handelt. Eines der einfachsten Clustering-Verfahren ist das sogenannte Gauß'sche Mixture-Modell (GMM), siehe\n",
    "\n",
    "> https://scikit-learn.org/stable/modules/generated/sklearn.mixture.GaussianMixture.html#sklearn.mixture.GaussianMixture\n",
    "\n",
    "Hier müssen wir allerdings Hyperparameter setzen. Insgesamt hat GMM 14 Hyperparameter. Wichtig ist allerdings nur erste Parameter `n_components`, der die Anzahl der Cluster vorgibt.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cd2c25-4b1e-4665-a72f-3c412e131549",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "# Wahl des Modells\n",
    "model = GaussianMixture(n_components=3)\n",
    "\n",
    "# Training des Modells mit allen Daten\n",
    "model.fit(X)\n",
    "\n",
    "# Prognose\n",
    "y_predict = model.predict(X)\n",
    "\n",
    "print(y_predict)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ced41f-50fc-47b9-91c5-63f1887d8a97",
   "metadata": {},
   "source": [
    "## Nachtrag: Import von Daten mit Pandas\n",
    "\n",
    "In dieser Vorlesung gehen wir davon aus, dass alle Daten in einem csv-Format vorliegen, d.h. als comma separated values. Wir lesen die Daten mit Pandas ein, die Dokumentation der Funktion ``read_csv()`` finden Sie hier:\n",
    "\n",
    "> https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html\n",
    "\n",
    "Folgende optionale Parameter hat die Funktion, die relevant sind:\n",
    "\n",
    "* **sep**: Hiermit wird das Trennzeichen angegeben. Normalerweise sind die Daten durch ein Komma getrennt, aber manchmal wird auch ein Leerzeichen, ein Tabulator oder ein Strichpunkt/Semikolon verwendet. Falls dem so ist, kann man hier das Trennzeichen beim import angeben, also z.B. ``sep=';'``, falls die Daten durch Strichpunkt getrennt sind. Beispiel: ``data = pd.read_csv('beispieldatei.csv', sep=';')``.\n",
    "* **header**: Hier kann eine Zeilennummer angegeben werden. Die Einträge in dieser Zeile werden dann als Spalennamen übernommen. Da die Überschriften der Spaltenin der csv-Datei normalerweise in der 1. Zeile, also Zeile 0, stehen, ist der Standardwert ``header=0`` voreingestellt. \n",
    "* **index_col**: Mit diesem Parameter kann angegeben werden, welche Spalte als Zeilenindex übernommen werden soll. Wenn nichts angegeben wird, erzeugt Pandas einen impliziten Index von 0, 1, 2, usw.\n",
    "* **skiprows**: Manchmal werden in den ersten Zeilen Kommentare zu den Daten geschrieben. Beispielsweise, wann das letzte Mal die Daten aktualisiert wurden oder eine E-Mail-Adresse, an wen man sich wenden kann, wenn man Fragen hat. Diese Kommentarzeilen müssen beim Einlesen der Daten übersprungen werden. Mit ``skiprows=3`` werden beispielsweise die ersten drei Zeilen übersprungen. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d20c7c-f873-4563-a3a8-f712c1cfee23",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\"><b>Aufgabe 9.1</b></br>\n",
    "Laden Sie den Datensatz ``bundesliga_top7_offensive.csv``und filtern Sie die Daten nach Borussia Dortmund. \n",
    "\n",
    "* Wie viele Spieler N spielten in der Saison bei Borussia Dortmund?\n",
    "* Nummerieren Sie die Spieler von 0 bis N und plotten Sie die Spielnummer auf der x-Achse und die Anzahl der Spielminuten, die dieser Spieler eingesetzt wurde, auf der y-Achse. Könnte ein linearer Zusammenhang bestehen?\n",
    "* Trainieren Sie ein linares Regressionsmodell, das die Anzahl der Spielminuten in Abhängigkeit der Spielernummer beschreibt.\n",
    "* Angenommen, Borussia Dortmund hätte einen Spieler mehr eingekauft, sprich Nummer N+1. Wie viele Minuten wäre dieser Spieler wohl eingesetzt worden? Plausibel?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e22217-97c2-4cef-91c4-8df789499a1a",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\"><b>Aufgabe 9.2</b></br>\n",
    "Laden Sie den Datensatz ``bundesliga_top7_offensive.csv``und filtern Sie die Daten nach Borussia Dortmund. \n",
    "\n",
    "* Führen Sie ein Clustering der Spieler nach Toren durch. Verwenden Sie 4 Cluster.\n",
    "* Schreiben Sie eine schöne Ausgabe, die die Namen der Fußballer eines jeden Clusters gemeinsam mit den Toren des Fußballers ausgibt.\n",
    "* Wie viele Fußballer sind gemeinsam mit Erling Haaland in einem Cluster?\n",
    "* Was passiert mit Marco Reus, wenn Sie die Anzahl der Cluster von 4 auf 3 Cluster reduzieren. Mit wem ist er jetzt in einem Cluster?\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
